<!DOCTYPE html>
<html lang="bn">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Voice Assistant | Smart Experience</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">
    <style>
        body { background: #070b14; color: white; font-family: 'Inter', sans-serif; overflow: hidden; }
        .glass { background: rgba(255, 255, 255, 0.03); backdrop-filter: blur(20px); border: 1px solid rgba(255,255,255,0.1); }
        
        /* Voice Wave Animation */
        .wave-container { display: flex; align-items: center; justify-content: center; gap: 5px; height: 60px; }
        .bar { width: 4px; height: 10px; background: #3b82f6; border-radius: 10px; transition: 0.2s; }
        .animating .bar { animation: wave 1s ease-in-out infinite; }
        @keyframes wave {
            0%, 100% { height: 10px; background: #3b82f6; }
            50% { height: 50px; background: #8b5cf6; }
        }
        .bar:nth-child(2) { animation-delay: 0.1s; }
        .bar:nth-child(3) { animation-delay: 0.2s; }
        .bar:nth-child(4) { animation-delay: 0.3s; }
        .bar:nth-child(5) { animation-delay: 0.4s; }
    </style>
</head>
<body class="min-h-screen flex flex-col items-center justify-center">
    
    <div class="max-w-md w-full glass p-10 rounded-[3rem] text-center shadow-2xl mx-4">
        <h1 class="text-3xl font-bold mb-2 bg-gradient-to-r from-blue-400 to-purple-500 bg-clip-text text-transparent">AI Assistant</h1>
        <p class="text-slate-400 text-sm mb-10">আপনার কথা শোনার জন্য আমি প্রস্তুত</p>

        <div id="statusBox" class="mb-10">
            <div id="wave" class="wave-container">
                <div class="bar"></div><div class="bar"></div><div class="bar"></div><div class="bar"></div><div class="bar"></div>
            </div>
            <p id="statusText" class="mt-4 text-sm text-slate-500 font-medium tracking-widest uppercase">Tap to Speak</p>
        </div>

        <button id="micBtn" class="w-24 h-24 rounded-full bg-blue-600 flex items-center justify-center text-3xl shadow-[0_0_30px_rgba(59,130,246,0.5)] hover:scale-105 transition-all active:scale-95">
            <i class="fas fa-microphone"></i>
        </button>

        <div id="conversation" class="mt-10 text-left space-y-4 hidden">
            <div class="bg-blue-500/10 p-3 rounded-2xl border border-blue-500/20">
                <p class="text-xs text-blue-400 font-bold uppercase mb-1">You</p>
                <p id="userText" class="text-sm"></p>
            </div>
            <div class="bg-purple-500/10 p-3 rounded-2xl border border-purple-500/20">
                <p class="text-xs text-purple-400 font-bold uppercase mb-1">AI Assistant</p>
                <p id="aiResponse" class="text-sm"></p>
            </div>
        </div>
    </div>

    <script>
        let mediaRecorder;
        let audioChunks = [];
        const micBtn = document.getElementById('micBtn');
        const wave = document.getElementById('wave');
        const statusText = document.getElementById('statusText');

        micBtn.onclick = async () => {
            if (mediaRecorder && mediaRecorder.state === "recording") {
                mediaRecorder.stop();
                return;
            }

            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            mediaRecorder = new MediaRecorder(stream);
            audioChunks = [];

            mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
            
            mediaRecorder.onstart = () => {
                wave.classList.add('animating');
                micBtn.classList.replace('bg-blue-600', 'bg-red-500');
                statusText.innerText = "Listening...";
                statusText.classList.add('text-red-400');
            };

            mediaRecorder.onstop = async () => {
                wave.classList.remove('animating');
                micBtn.classList.replace('bg-red-500', 'bg-blue-600');
                statusText.innerText = "Processing...";
                
                const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                const formData = new FormData();
                formData.append('file', audioBlob, 'voice.wav');

                try {
                    const res = await fetch('/process-voice', { method: 'POST', body: formData });
                    const data = await res.json();
                    
                    if (data.error) {
                        alert(data.error);
                    } else {
                        document.getElementById('conversation').classList.remove('hidden');
                        document.getElementById('userText').innerText = data.user_text;
                        document.getElementById('aiResponse').innerText = data.ai_response;
                        
                        // Text to Speech logic (Web Speech API)
                        const speech = new SpeechSynthesisUtterance(data.ai_response);
                        window.speechSynthesis.speak(speech);
                    }
                } catch (e) { alert("Server Error!"); }
                
                statusText.innerText = "Tap to Speak";
            };

            mediaRecorder.start();
        };
    </script>
</body>
</html>